#!/usr/bin/env python
# coding: utf-8

import os
import pickle
import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from googleapiclient.discovery import build
from google.auth.transport.requests import Request

# ==========================
# Google Sheets è¨­å®š
# ==========================
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
TOKEN_PICKLE_FILE = 'token.pickle'
SPREADSHEET_ID = "12ub3XFQtIeBPU93dD3T4Nv4GaLT7TtnLoaFteEcYM4A"
TARGET_SHEET = "xAI"

def get_credentials():
    if not os.path.exists(TOKEN_PICKLE_FILE):
        raise Exception("âŒ token.pickle ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
    with open(TOKEN_PICKLE_FILE, 'rb') as f:
        creds = pickle.load(f)
    if not creds.valid:
        if creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            raise Exception("âŒ OAuth ãƒˆãƒ¼ã‚¯ãƒ³ãŒç„¡åŠ¹ã§ã™ã€‚")
    return creds

def write_to_sheet(data):
    try:
        creds = get_credentials()
        service = build('sheets', 'v4', credentials=creds)
        sheet = service.spreadsheets()
        
        if data:
            # 2è¡Œç›®ä»¥é™ã‚’ã‚¯ãƒªã‚¢
            sheet.values().clear(
                spreadsheetId=SPREADSHEET_ID, 
                range=f"{TARGET_SHEET}!A2:Z1000"
            ).execute()
            
            # A2ã‚»ãƒ«ã‹ã‚‰æ›¸ãè¾¼ã¿
            sheet.values().update(
                spreadsheetId=SPREADSHEET_ID,
                range=f"{TARGET_SHEET}!A2",
                valueInputOption="RAW",
                body={"values": data}
            ).execute()
            print(f"âœ… {len(data)} è¡Œã‚’ {TARGET_SHEET} ã‚·ãƒ¼ãƒˆã«è»¢è¨˜ã—ã¾ã—ãŸã€‚")
        else:
            print("âš ï¸ è»¢è¨˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    except Exception as e:
         print(f"âš ï¸ æ›¸ãè¾¼ã¿å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def init_webdriver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    # GitHub Actionsã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚„ã™ã„è¨€èªè¨­å®šã‚’å›ºå®š
    options.add_argument("--lang=ja-JP")
    return webdriver.Chrome(options=options)

# ==========================
# ã‚¯ãƒ­ãƒ¼ãƒ«å‡¦ç† (ä¿®æ­£ç‰ˆ)
# ==========================
def scrape_xai_models():
    url = "https://artificialanalysis.ai/providers/xai"
    driver = init_webdriver()
    rows_data = []
    
    try:
        print(f"ğŸ” ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")
        driver.get(url)
        wait = WebDriverWait(driver, 20)
        
        # 1. ç¢ºå®Ÿã«å­˜åœ¨ã™ã‚‹è¦ªã‚³ãƒ³ãƒ†ãƒŠã‚’å¾…æ©Ÿ
        # ã‚¯ãƒ©ã‚¹åã«ã‚¹ãƒšãƒ¼ã‚¹ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ .class1.class2 ã®å½¢å¼ã§æŒ‡å®š
        parent_container = wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR, ".container.m-auto.pb-8"))
        )
        print("âœ… è¦ªã‚³ãƒ³ãƒ†ãƒŠã‚’ç¢ºèªã—ã¾ã—ãŸã€‚")

        # 2. è¦ªã‚³ãƒ³ãƒ†ãƒŠã®ä¸­ã«ã‚ã‚‹ tbody ã‚’å–å¾—
        # ã‚¯ãƒ©ã‚¹å [&_tr:last-child]:border-0 ã¯ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãŸã‚ CSS ã‚»ãƒ¬ã‚¯ã‚¿ã‚’ä½¿ã‚ãšã€
        # æ§‹é€ çš„ã«ã€Œcontainerå†…ã®æœ€åˆï¼ˆã¾ãŸã¯å”¯ä¸€ï¼‰ã®tbodyã€ã‚’æ¢ã™ã®ãŒå®‰å…¨ã§ã™
        tbody = parent_container.find_element(By.TAG_NAME, "tbody")
        
        # 3. tbody å†…ã®ã™ã¹ã¦ã®è¡Œ (tr) ã‚’å–å¾—
        rows = tbody.find_elements(By.TAG_NAME, "tr")
        print(f"ğŸ“Š {len(rows)} å€‹ã®è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚è§£æã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        
        for row in rows:
            cells = row.find_elements(By.TAG_NAME, "td")
            if not cells:
                continue
                
            # æ–‡å­—åˆ—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦ãƒªã‚¹ãƒˆåŒ–
            row_content = [cell.text.strip().replace('\n', ' ') for cell in cells]
            if any(row_content):
                rows_data.append(row_content)
                
    except Exception as e:
        print(f"âš ï¸ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        driver.quit()
    
    return rows_data

if __name__ == "__main__":
    try:
        extracted_data = scrape_xai_models()
        if extracted_data:
            write_to_sheet(extracted_data)
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µã‚¤ãƒˆã®æ§‹é€ ãŒå¤‰æ›´ã•ã‚ŒãŸã‹ã€ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ãŒé–“ã«åˆã£ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    except Exception as e:
        print(f"è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
